{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "Arrow Classification - Colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newb-dev-1008/IRC-Rover-Files/blob/master/Arrow%20Classification%20-%20Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDmxl3kpzzyu"
      },
      "source": [
        "import os \n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gKqP1B5yZ6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf7d7a1-4315-4d3e-cbef-245b826fec88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4TGfFLCzzy7"
      },
      "source": [
        "# Store input data with respective labels\n",
        "\n",
        "# Path to folder containing the datasets\n",
        "inputPaths = \"/content/drive/MyDrive/College Stuff (B.Tech.)/7th Sem/IRC/Final Datasets for Training\"\n",
        "\n",
        "# All possible labels/ directions\n",
        "labels = []\n",
        "\n",
        "# List to store the paths of all images in the dataset\n",
        "imagePaths = list(paths.list_images(inputPaths))\n",
        "\n",
        "# This list will be used to store all the images in Bitmap format from OpenCV's imread()\n",
        "images = []\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    labels.append(label)\n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (64, 64))\n",
        "    \n",
        "    images.append(image)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH6UVsjqzzy9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# One-hot encoding of labels to deal with categorical data\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "\n",
        "# Partition the datasets for training and validation (75% train : 25% test)\n",
        "(trainX, testX, trainY, testY) = train_test_split(images, labels, test_size = 0.25, stratify = labels)\n",
        "\n",
        "# Initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator(rotation_range = 0,\n",
        "                             zoom_range = 0.15, \n",
        "                             width_shift_range = 0.15, \n",
        "                             height_shift_range = 0.15, \n",
        "                             shear_range = 0.15, \n",
        "                             horizontal_flip = False,\n",
        "                             fill_mode = 'nearest')\n",
        "\n",
        "# Initialize the validation data augmentation object\n",
        "valAug = ImageDataGenerator()\n",
        "\n",
        "# Define the ImageNet Mean Subtraction (in RGB order) and set mean subtraction value \n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean\n",
        "n_epochs = 50"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_x88-LMXVRk"
      },
      "source": [
        "# **Trial with CNN (ResNet - 50)**\n",
        "\n",
        "Overkill, may be prone to overfitting. Check below for SVM classifier approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTGIWCUVXU5n"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwoEOKYpY9Zu",
        "outputId": "f5365668-ac38-4eef-a902-49bb9bda76ba"
      },
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-zZ9TGEYt0r",
        "outputId": "f7441397-a7f6-499e-dadd-c887c4a1c817"
      },
      "source": [
        "with tf.device('/GPU:0'):\n",
        "\n",
        "    # Changed my mind on number of epochs\n",
        "    n_epochs = 30\n",
        "\n",
        "    # Load the ResNet - 50 model, with it's fully connected layers removed\n",
        "    baseModel = ResNet50(weights = \"imagenet\", include_top = False, input_tensor = Input(shape = (64, 64, 3)))\n",
        "\n",
        "    # Construct the fully connected layers to be placed on top of baseModel\n",
        "    headModel = baseModel.output\n",
        "    headModel = AveragePooling2D(pool_size = (1, 1))(headModel)\n",
        "    headModel = Flatten(name = \"Flatten_1\")(headModel)\n",
        "    headModel = Dense(128, activation = \"relu\")(headModel)\n",
        "    headModel = Dropout(0.5)(headModel)\n",
        "    headModel = Dense(len(lb.classes_), activation = \"softmax\")(headModel)\n",
        "\n",
        "    # Connect the baseModel and headModel\n",
        "    model = Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "    # Loop through all layers of baseModel and freeze them (make them untrainable)\n",
        "    # This is necessary to ensure that the ResNet50 weights don't get updated during the process\n",
        "    for layer in baseModel.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Compile the model (after making baseModel non-trainable)\n",
        "    model.compile(loss = \"categorical_crossentropy\",\n",
        "                  optimizer = SGD(lr = 1e-4, momentum = 0.9, decay = (1e-4 / n_epochs)),\n",
        "                  metrics = [\"accuracy\"])\n",
        "    \n",
        "    # Train the model for n_epochs\n",
        "    H = model.fit(x = trainAug.flow(trainX, trainY, batch_size = 4),\n",
        "                  steps_per_epoch = len(trainX) // 4,\n",
        "                  validation_data = valAug.flow(testX, testY),\n",
        "                  validation_steps = len(testX) // 4,\n",
        "                  epochs = n_epochs)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "202/203 [============================>.] - ETA: 0s - loss: 1.5709 - accuracy: 0.4517WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 67 batches). You may need to use the repeat() function when building your dataset.\n",
            "203/203 [==============================] - 6s 19ms/step - loss: 1.5670 - accuracy: 0.4520 - val_loss: 0.8490 - val_accuracy: 0.6199\n",
            "Epoch 2/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.9751 - accuracy: 0.5874\n",
            "Epoch 3/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.7826 - accuracy: 0.6502\n",
            "Epoch 4/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.7388 - accuracy: 0.6502\n",
            "Epoch 5/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.6828 - accuracy: 0.6970\n",
            "Epoch 6/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.6324 - accuracy: 0.7204\n",
            "Epoch 7/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.5900 - accuracy: 0.7488\n",
            "Epoch 8/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.6087 - accuracy: 0.7414\n",
            "Epoch 9/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.5534 - accuracy: 0.7401\n",
            "Epoch 10/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.5726 - accuracy: 0.7389\n",
            "Epoch 11/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.5270 - accuracy: 0.7623\n",
            "Epoch 12/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.5308 - accuracy: 0.7759\n",
            "Epoch 13/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4636 - accuracy: 0.7993\n",
            "Epoch 14/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.5047 - accuracy: 0.7906\n",
            "Epoch 15/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4484 - accuracy: 0.8214\n",
            "Epoch 16/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4472 - accuracy: 0.8091\n",
            "Epoch 17/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4598 - accuracy: 0.7993\n",
            "Epoch 18/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4342 - accuracy: 0.8091\n",
            "Epoch 19/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4271 - accuracy: 0.8017\n",
            "Epoch 20/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4152 - accuracy: 0.8202\n",
            "Epoch 21/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4088 - accuracy: 0.8153\n",
            "Epoch 22/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.4189 - accuracy: 0.8030\n",
            "Epoch 23/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.4220 - accuracy: 0.8202\n",
            "Epoch 24/30\n",
            "203/203 [==============================] - 3s 13ms/step - loss: 0.4194 - accuracy: 0.8436\n",
            "Epoch 25/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3852 - accuracy: 0.8313\n",
            "Epoch 26/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3682 - accuracy: 0.8547\n",
            "Epoch 27/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3652 - accuracy: 0.8288\n",
            "Epoch 28/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3834 - accuracy: 0.8399\n",
            "Epoch 29/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3715 - accuracy: 0.8608\n",
            "Epoch 30/30\n",
            "203/203 [==============================] - 3s 14ms/step - loss: 0.3562 - accuracy: 0.8707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "iqPpd9p5oWvH",
        "outputId": "847aa793-258f-4afe-d228-c3103b2da9f2"
      },
      "source": [
        "# Evaluate network\n",
        "print(\"Evaluating the network:\\n\")\n",
        "predictions = model.predict(x = testX.astype(\"float32\"), batch_size = 4)\n",
        "\n",
        "# Return precision, recall, F1 score\n",
        "print(classification_report(testY.argmax(axis = 1), predictions.argmax(axis = 1), target_names = lb.classes_))\n",
        "\n",
        "N = n_epochs\n",
        "\n",
        "# Plot training loss and accuracy\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label = \"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label = \"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label = \"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label = \"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/ Accuracy\")\n",
        "plt.legend(loc = \"lower left\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating the network:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Left       0.73      0.78      0.76        88\n",
            "       Right       0.79      0.75      0.77        89\n",
            "    Straight       0.89      0.87      0.88        94\n",
            "\n",
            "    accuracy                           0.80       271\n",
            "   macro avg       0.80      0.80      0.80       271\n",
            "weighted avg       0.81      0.80      0.80       271\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-dd2de57235b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U2V-sKZqqhl",
        "outputId": "05988c90-856b-4221-fe82-fbbe01f4b956"
      },
      "source": [
        "# Save the trained model\n",
        "modelPath = \"/content/drive/MyDrive/College Stuff (B.Tech.)/7th Sem/IRC/Saved Models/ResNet - 50/trained_arrow\"\n",
        "model.save(modelPath, save_format = \"h5\")\n",
        "\n",
        "# Serialize the LabelBinarizer as well\n",
        "lbPath = \"/content/drive/MyDrive/College Stuff (B.Tech.)/7th Sem/IRC/Saved Models/ResNet - 50/lb_arrow.pickle\"\n",
        "with open(lbPath, \"wb\") as f:\n",
        "    f.write(pickle.dumps(lb))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB8ESQFIzzy_"
      },
      "source": [
        "## **Classification with Plain SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7mt57kozzzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f7dc94-c84a-49a3-bcf9-8ddb8329bc81"
      },
      "source": [
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "\n",
        "# Path to folder containing the datasets\n",
        "inputPaths = \"/content/drive/MyDrive/IRC Datasets/Final Datasets for Training\"\n",
        "\n",
        "# All possible labels/ directions\n",
        "labels = []\n",
        "\n",
        "# List to store the paths of all images in the dataset\n",
        "imagePaths = list(paths.list_images(inputPaths))\n",
        "\n",
        "# This list will be used to store all the images in Bitmap format from OpenCV's imread()\n",
        "images = []\n",
        "\n",
        "i = 0\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    labels.append(label)\n",
        "    \n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (64, 64))\n",
        "    print(\"Added image: \", i)\n",
        "    i += 1\n",
        "    \n",
        "    images.append(image.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Added image:  0\n",
            "Added image:  1\n",
            "Added image:  2\n",
            "Added image:  3\n",
            "Added image:  4\n",
            "Added image:  5\n",
            "Added image:  6\n",
            "Added image:  7\n",
            "Added image:  8\n",
            "Added image:  9\n",
            "Added image:  10\n",
            "Added image:  11\n",
            "Added image:  12\n",
            "Added image:  13\n",
            "Added image:  14\n",
            "Added image:  15\n",
            "Added image:  16\n",
            "Added image:  17\n",
            "Added image:  18\n",
            "Added image:  19\n",
            "Added image:  20\n",
            "Added image:  21\n",
            "Added image:  22\n",
            "Added image:  23\n",
            "Added image:  24\n",
            "Added image:  25\n",
            "Added image:  26\n",
            "Added image:  27\n",
            "Added image:  28\n",
            "Added image:  29\n",
            "Added image:  30\n",
            "Added image:  31\n",
            "Added image:  32\n",
            "Added image:  33\n",
            "Added image:  34\n",
            "Added image:  35\n",
            "Added image:  36\n",
            "Added image:  37\n",
            "Added image:  38\n",
            "Added image:  39\n",
            "Added image:  40\n",
            "Added image:  41\n",
            "Added image:  42\n",
            "Added image:  43\n",
            "Added image:  44\n",
            "Added image:  45\n",
            "Added image:  46\n",
            "Added image:  47\n",
            "Added image:  48\n",
            "Added image:  49\n",
            "Added image:  50\n",
            "Added image:  51\n",
            "Added image:  52\n",
            "Added image:  53\n",
            "Added image:  54\n",
            "Added image:  55\n",
            "Added image:  56\n",
            "Added image:  57\n",
            "Added image:  58\n",
            "Added image:  59\n",
            "Added image:  60\n",
            "Added image:  61\n",
            "Added image:  62\n",
            "Added image:  63\n",
            "Added image:  64\n",
            "Added image:  65\n",
            "Added image:  66\n",
            "Added image:  67\n",
            "Added image:  68\n",
            "Added image:  69\n",
            "Added image:  70\n",
            "Added image:  71\n",
            "Added image:  72\n",
            "Added image:  73\n",
            "Added image:  74\n",
            "Added image:  75\n",
            "Added image:  76\n",
            "Added image:  77\n",
            "Added image:  78\n",
            "Added image:  79\n",
            "Added image:  80\n",
            "Added image:  81\n",
            "Added image:  82\n",
            "Added image:  83\n",
            "Added image:  84\n",
            "Added image:  85\n",
            "Added image:  86\n",
            "Added image:  87\n",
            "Added image:  88\n",
            "Added image:  89\n",
            "Added image:  90\n",
            "Added image:  91\n",
            "Added image:  92\n",
            "Added image:  93\n",
            "Added image:  94\n",
            "Added image:  95\n",
            "Added image:  96\n",
            "Added image:  97\n",
            "Added image:  98\n",
            "Added image:  99\n",
            "Added image:  100\n",
            "Added image:  101\n",
            "Added image:  102\n",
            "Added image:  103\n",
            "Added image:  104\n",
            "Added image:  105\n",
            "Added image:  106\n",
            "Added image:  107\n",
            "Added image:  108\n",
            "Added image:  109\n",
            "Added image:  110\n",
            "Added image:  111\n",
            "Added image:  112\n",
            "Added image:  113\n",
            "Added image:  114\n",
            "Added image:  115\n",
            "Added image:  116\n",
            "Added image:  117\n",
            "Added image:  118\n",
            "Added image:  119\n",
            "Added image:  120\n",
            "Added image:  121\n",
            "Added image:  122\n",
            "Added image:  123\n",
            "Added image:  124\n",
            "Added image:  125\n",
            "Added image:  126\n",
            "Added image:  127\n",
            "Added image:  128\n",
            "Added image:  129\n",
            "Added image:  130\n",
            "Added image:  131\n",
            "Added image:  132\n",
            "Added image:  133\n",
            "Added image:  134\n",
            "Added image:  135\n",
            "Added image:  136\n",
            "Added image:  137\n",
            "Added image:  138\n",
            "Added image:  139\n",
            "Added image:  140\n",
            "Added image:  141\n",
            "Added image:  142\n",
            "Added image:  143\n",
            "Added image:  144\n",
            "Added image:  145\n",
            "Added image:  146\n",
            "Added image:  147\n",
            "Added image:  148\n",
            "Added image:  149\n",
            "Added image:  150\n",
            "Added image:  151\n",
            "Added image:  152\n",
            "Added image:  153\n",
            "Added image:  154\n",
            "Added image:  155\n",
            "Added image:  156\n",
            "Added image:  157\n",
            "Added image:  158\n",
            "Added image:  159\n",
            "Added image:  160\n",
            "Added image:  161\n",
            "Added image:  162\n",
            "Added image:  163\n",
            "Added image:  164\n",
            "Added image:  165\n",
            "Added image:  166\n",
            "Added image:  167\n",
            "Added image:  168\n",
            "Added image:  169\n",
            "Added image:  170\n",
            "Added image:  171\n",
            "Added image:  172\n",
            "Added image:  173\n",
            "Added image:  174\n",
            "Added image:  175\n",
            "Added image:  176\n",
            "Added image:  177\n",
            "Added image:  178\n",
            "Added image:  179\n",
            "Added image:  180\n",
            "Added image:  181\n",
            "Added image:  182\n",
            "Added image:  183\n",
            "Added image:  184\n",
            "Added image:  185\n",
            "Added image:  186\n",
            "Added image:  187\n",
            "Added image:  188\n",
            "Added image:  189\n",
            "Added image:  190\n",
            "Added image:  191\n",
            "Added image:  192\n",
            "Added image:  193\n",
            "Added image:  194\n",
            "Added image:  195\n",
            "Added image:  196\n",
            "Added image:  197\n",
            "Added image:  198\n",
            "Added image:  199\n",
            "Added image:  200\n",
            "Added image:  201\n",
            "Added image:  202\n",
            "Added image:  203\n",
            "Added image:  204\n",
            "Added image:  205\n",
            "Added image:  206\n",
            "Added image:  207\n",
            "Added image:  208\n",
            "Added image:  209\n",
            "Added image:  210\n",
            "Added image:  211\n",
            "Added image:  212\n",
            "Added image:  213\n",
            "Added image:  214\n",
            "Added image:  215\n",
            "Added image:  216\n",
            "Added image:  217\n",
            "Added image:  218\n",
            "Added image:  219\n",
            "Added image:  220\n",
            "Added image:  221\n",
            "Added image:  222\n",
            "Added image:  223\n",
            "Added image:  224\n",
            "Added image:  225\n",
            "Added image:  226\n",
            "Added image:  227\n",
            "Added image:  228\n",
            "Added image:  229\n",
            "Added image:  230\n",
            "Added image:  231\n",
            "Added image:  232\n",
            "Added image:  233\n",
            "Added image:  234\n",
            "Added image:  235\n",
            "Added image:  236\n",
            "Added image:  237\n",
            "Added image:  238\n",
            "Added image:  239\n",
            "Added image:  240\n",
            "Added image:  241\n",
            "Added image:  242\n",
            "Added image:  243\n",
            "Added image:  244\n",
            "Added image:  245\n",
            "Added image:  246\n",
            "Added image:  247\n",
            "Added image:  248\n",
            "Added image:  249\n",
            "Added image:  250\n",
            "Added image:  251\n",
            "Added image:  252\n",
            "Added image:  253\n",
            "Added image:  254\n",
            "Added image:  255\n",
            "Added image:  256\n",
            "Added image:  257\n",
            "Added image:  258\n",
            "Added image:  259\n",
            "Added image:  260\n",
            "Added image:  261\n",
            "Added image:  262\n",
            "Added image:  263\n",
            "Added image:  264\n",
            "Added image:  265\n",
            "Added image:  266\n",
            "Added image:  267\n",
            "Added image:  268\n",
            "Added image:  269\n",
            "Added image:  270\n",
            "Added image:  271\n",
            "Added image:  272\n",
            "Added image:  273\n",
            "Added image:  274\n",
            "Added image:  275\n",
            "Added image:  276\n",
            "Added image:  277\n",
            "Added image:  278\n",
            "Added image:  279\n",
            "Added image:  280\n",
            "Added image:  281\n",
            "Added image:  282\n",
            "Added image:  283\n",
            "Added image:  284\n",
            "Added image:  285\n",
            "Added image:  286\n",
            "Added image:  287\n",
            "Added image:  288\n",
            "Added image:  289\n",
            "Added image:  290\n",
            "Added image:  291\n",
            "Added image:  292\n",
            "Added image:  293\n",
            "Added image:  294\n",
            "Added image:  295\n",
            "Added image:  296\n",
            "Added image:  297\n",
            "Added image:  298\n",
            "Added image:  299\n",
            "Added image:  300\n",
            "Added image:  301\n",
            "Added image:  302\n",
            "Added image:  303\n",
            "Added image:  304\n",
            "Added image:  305\n",
            "Added image:  306\n",
            "Added image:  307\n",
            "Added image:  308\n",
            "Added image:  309\n",
            "Added image:  310\n",
            "Added image:  311\n",
            "Added image:  312\n",
            "Added image:  313\n",
            "Added image:  314\n",
            "Added image:  315\n",
            "Added image:  316\n",
            "Added image:  317\n",
            "Added image:  318\n",
            "Added image:  319\n",
            "Added image:  320\n",
            "Added image:  321\n",
            "Added image:  322\n",
            "Added image:  323\n",
            "Added image:  324\n",
            "Added image:  325\n",
            "Added image:  326\n",
            "Added image:  327\n",
            "Added image:  328\n",
            "Added image:  329\n",
            "Added image:  330\n",
            "Added image:  331\n",
            "Added image:  332\n",
            "Added image:  333\n",
            "Added image:  334\n",
            "Added image:  335\n",
            "Added image:  336\n",
            "Added image:  337\n",
            "Added image:  338\n",
            "Added image:  339\n",
            "Added image:  340\n",
            "Added image:  341\n",
            "Added image:  342\n",
            "Added image:  343\n",
            "Added image:  344\n",
            "Added image:  345\n",
            "Added image:  346\n",
            "Added image:  347\n",
            "Added image:  348\n",
            "Added image:  349\n",
            "Added image:  350\n",
            "Added image:  351\n",
            "Added image:  352\n",
            "Added image:  353\n",
            "Added image:  354\n",
            "Added image:  355\n",
            "Added image:  356\n",
            "Added image:  357\n",
            "Added image:  358\n",
            "Added image:  359\n",
            "Added image:  360\n",
            "Added image:  361\n",
            "Added image:  362\n",
            "Added image:  363\n",
            "Added image:  364\n",
            "Added image:  365\n",
            "Added image:  366\n",
            "Added image:  367\n",
            "Added image:  368\n",
            "Added image:  369\n",
            "Added image:  370\n",
            "Added image:  371\n",
            "Added image:  372\n",
            "Added image:  373\n",
            "Added image:  374\n",
            "Added image:  375\n",
            "Added image:  376\n",
            "Added image:  377\n",
            "Added image:  378\n",
            "Added image:  379\n",
            "Added image:  380\n",
            "Added image:  381\n",
            "Added image:  382\n",
            "Added image:  383\n",
            "Added image:  384\n",
            "Added image:  385\n",
            "Added image:  386\n",
            "Added image:  387\n",
            "Added image:  388\n",
            "Added image:  389\n",
            "Added image:  390\n",
            "Added image:  391\n",
            "Added image:  392\n",
            "Added image:  393\n",
            "Added image:  394\n",
            "Added image:  395\n",
            "Added image:  396\n",
            "Added image:  397\n",
            "Added image:  398\n",
            "Added image:  399\n",
            "Added image:  400\n",
            "Added image:  401\n",
            "Added image:  402\n",
            "Added image:  403\n",
            "Added image:  404\n",
            "Added image:  405\n",
            "Added image:  406\n",
            "Added image:  407\n",
            "Added image:  408\n",
            "Added image:  409\n",
            "Added image:  410\n",
            "Added image:  411\n",
            "Added image:  412\n",
            "Added image:  413\n",
            "Added image:  414\n",
            "Added image:  415\n",
            "Added image:  416\n",
            "Added image:  417\n",
            "Added image:  418\n",
            "Added image:  419\n",
            "Added image:  420\n",
            "Added image:  421\n",
            "Added image:  422\n",
            "Added image:  423\n",
            "Added image:  424\n",
            "Added image:  425\n",
            "Added image:  426\n",
            "Added image:  427\n",
            "Added image:  428\n",
            "Added image:  429\n",
            "Added image:  430\n",
            "Added image:  431\n",
            "Added image:  432\n",
            "Added image:  433\n",
            "Added image:  434\n",
            "Added image:  435\n",
            "Added image:  436\n",
            "Added image:  437\n",
            "Added image:  438\n",
            "Added image:  439\n",
            "Added image:  440\n",
            "Added image:  441\n",
            "Added image:  442\n",
            "Added image:  443\n",
            "Added image:  444\n",
            "Added image:  445\n",
            "Added image:  446\n",
            "Added image:  447\n",
            "Added image:  448\n",
            "Added image:  449\n",
            "Added image:  450\n",
            "Added image:  451\n",
            "Added image:  452\n",
            "Added image:  453\n",
            "Added image:  454\n",
            "Added image:  455\n",
            "Added image:  456\n",
            "Added image:  457\n",
            "Added image:  458\n",
            "Added image:  459\n",
            "Added image:  460\n",
            "Added image:  461\n",
            "Added image:  462\n",
            "Added image:  463\n",
            "Added image:  464\n",
            "Added image:  465\n",
            "Added image:  466\n",
            "Added image:  467\n",
            "Added image:  468\n",
            "Added image:  469\n",
            "Added image:  470\n",
            "Added image:  471\n",
            "Added image:  472\n",
            "Added image:  473\n",
            "Added image:  474\n",
            "Added image:  475\n",
            "Added image:  476\n",
            "Added image:  477\n",
            "Added image:  478\n",
            "Added image:  479\n",
            "Added image:  480\n",
            "Added image:  481\n",
            "Added image:  482\n",
            "Added image:  483\n",
            "Added image:  484\n",
            "Added image:  485\n",
            "Added image:  486\n",
            "Added image:  487\n",
            "Added image:  488\n",
            "Added image:  489\n",
            "Added image:  490\n",
            "Added image:  491\n",
            "Added image:  492\n",
            "Added image:  493\n",
            "Added image:  494\n",
            "Added image:  495\n",
            "Added image:  496\n",
            "Added image:  497\n",
            "Added image:  498\n",
            "Added image:  499\n",
            "Added image:  500\n",
            "Added image:  501\n",
            "Added image:  502\n",
            "Added image:  503\n",
            "Added image:  504\n",
            "Added image:  505\n",
            "Added image:  506\n",
            "Added image:  507\n",
            "Added image:  508\n",
            "Added image:  509\n",
            "Added image:  510\n",
            "Added image:  511\n",
            "Added image:  512\n",
            "Added image:  513\n",
            "Added image:  514\n",
            "Added image:  515\n",
            "Added image:  516\n",
            "Added image:  517\n",
            "Added image:  518\n",
            "Added image:  519\n",
            "Added image:  520\n",
            "Added image:  521\n",
            "Added image:  522\n",
            "Added image:  523\n",
            "Added image:  524\n",
            "Added image:  525\n",
            "Added image:  526\n",
            "Added image:  527\n",
            "Added image:  528\n",
            "Added image:  529\n",
            "Added image:  530\n",
            "Added image:  531\n",
            "Added image:  532\n",
            "Added image:  533\n",
            "Added image:  534\n",
            "Added image:  535\n",
            "Added image:  536\n",
            "Added image:  537\n",
            "Added image:  538\n",
            "Added image:  539\n",
            "Added image:  540\n",
            "Added image:  541\n",
            "Added image:  542\n",
            "Added image:  543\n",
            "Added image:  544\n",
            "Added image:  545\n",
            "Added image:  546\n",
            "Added image:  547\n",
            "Added image:  548\n",
            "Added image:  549\n",
            "Added image:  550\n",
            "Added image:  551\n",
            "Added image:  552\n",
            "Added image:  553\n",
            "Added image:  554\n",
            "Added image:  555\n",
            "Added image:  556\n",
            "Added image:  557\n",
            "Added image:  558\n",
            "Added image:  559\n",
            "Added image:  560\n",
            "Added image:  561\n",
            "Added image:  562\n",
            "Added image:  563\n",
            "Added image:  564\n",
            "Added image:  565\n",
            "Added image:  566\n",
            "Added image:  567\n",
            "Added image:  568\n",
            "Added image:  569\n",
            "Added image:  570\n",
            "Added image:  571\n",
            "Added image:  572\n",
            "Added image:  573\n",
            "Added image:  574\n",
            "Added image:  575\n",
            "Added image:  576\n",
            "Added image:  577\n",
            "Added image:  578\n",
            "Added image:  579\n",
            "Added image:  580\n",
            "Added image:  581\n",
            "Added image:  582\n",
            "Added image:  583\n",
            "Added image:  584\n",
            "Added image:  585\n",
            "Added image:  586\n",
            "Added image:  587\n",
            "Added image:  588\n",
            "Added image:  589\n",
            "Added image:  590\n",
            "Added image:  591\n",
            "Added image:  592\n",
            "Added image:  593\n",
            "Added image:  594\n",
            "Added image:  595\n",
            "Added image:  596\n",
            "Added image:  597\n",
            "Added image:  598\n",
            "Added image:  599\n",
            "Added image:  600\n",
            "Added image:  601\n",
            "Added image:  602\n",
            "Added image:  603\n",
            "Added image:  604\n",
            "Added image:  605\n",
            "Added image:  606\n",
            "Added image:  607\n",
            "Added image:  608\n",
            "Added image:  609\n",
            "Added image:  610\n",
            "Added image:  611\n",
            "Added image:  612\n",
            "Added image:  613\n",
            "Added image:  614\n",
            "Added image:  615\n",
            "Added image:  616\n",
            "Added image:  617\n",
            "Added image:  618\n",
            "Added image:  619\n",
            "Added image:  620\n",
            "Added image:  621\n",
            "Added image:  622\n",
            "Added image:  623\n",
            "Added image:  624\n",
            "Added image:  625\n",
            "Added image:  626\n",
            "Added image:  627\n",
            "Added image:  628\n",
            "Added image:  629\n",
            "Added image:  630\n",
            "Added image:  631\n",
            "Added image:  632\n",
            "Added image:  633\n",
            "Added image:  634\n",
            "Added image:  635\n",
            "Added image:  636\n",
            "Added image:  637\n",
            "Added image:  638\n",
            "Added image:  639\n",
            "Added image:  640\n",
            "Added image:  641\n",
            "Added image:  642\n",
            "Added image:  643\n",
            "Added image:  644\n",
            "Added image:  645\n",
            "Added image:  646\n",
            "Added image:  647\n",
            "Added image:  648\n",
            "Added image:  649\n",
            "Added image:  650\n",
            "Added image:  651\n",
            "Added image:  652\n",
            "Added image:  653\n",
            "Added image:  654\n",
            "Added image:  655\n",
            "Added image:  656\n",
            "Added image:  657\n",
            "Added image:  658\n",
            "Added image:  659\n",
            "Added image:  660\n",
            "Added image:  661\n",
            "Added image:  662\n",
            "Added image:  663\n",
            "Added image:  664\n",
            "Added image:  665\n",
            "Added image:  666\n",
            "Added image:  667\n",
            "Added image:  668\n",
            "Added image:  669\n",
            "Added image:  670\n",
            "Added image:  671\n",
            "Added image:  672\n",
            "Added image:  673\n",
            "Added image:  674\n",
            "Added image:  675\n",
            "Added image:  676\n",
            "Added image:  677\n",
            "Added image:  678\n",
            "Added image:  679\n",
            "Added image:  680\n",
            "Added image:  681\n",
            "Added image:  682\n",
            "Added image:  683\n",
            "Added image:  684\n",
            "Added image:  685\n",
            "Added image:  686\n",
            "Added image:  687\n",
            "Added image:  688\n",
            "Added image:  689\n",
            "Added image:  690\n",
            "Added image:  691\n",
            "Added image:  692\n",
            "Added image:  693\n",
            "Added image:  694\n",
            "Added image:  695\n",
            "Added image:  696\n",
            "Added image:  697\n",
            "Added image:  698\n",
            "Added image:  699\n",
            "Added image:  700\n",
            "Added image:  701\n",
            "Added image:  702\n",
            "Added image:  703\n",
            "Added image:  704\n",
            "Added image:  705\n",
            "Added image:  706\n",
            "Added image:  707\n",
            "Added image:  708\n",
            "Added image:  709\n",
            "Added image:  710\n",
            "Added image:  711\n",
            "Added image:  712\n",
            "Added image:  713\n",
            "Added image:  714\n",
            "Added image:  715\n",
            "Added image:  716\n",
            "Added image:  717\n",
            "Added image:  718\n",
            "Added image:  719\n",
            "Added image:  720\n",
            "Added image:  721\n",
            "Added image:  722\n",
            "Added image:  723\n",
            "Added image:  724\n",
            "Added image:  725\n",
            "Added image:  726\n",
            "Added image:  727\n",
            "Added image:  728\n",
            "Added image:  729\n",
            "Added image:  730\n",
            "Added image:  731\n",
            "Added image:  732\n",
            "Added image:  733\n",
            "Added image:  734\n",
            "Added image:  735\n",
            "Added image:  736\n",
            "Added image:  737\n",
            "Added image:  738\n",
            "Added image:  739\n",
            "Added image:  740\n",
            "Added image:  741\n",
            "Added image:  742\n",
            "Added image:  743\n",
            "Added image:  744\n",
            "Added image:  745\n",
            "Added image:  746\n",
            "Added image:  747\n",
            "Added image:  748\n",
            "Added image:  749\n",
            "Added image:  750\n",
            "Added image:  751\n",
            "Added image:  752\n",
            "Added image:  753\n",
            "Added image:  754\n",
            "Added image:  755\n",
            "Added image:  756\n",
            "Added image:  757\n",
            "Added image:  758\n",
            "Added image:  759\n",
            "Added image:  760\n",
            "Added image:  761\n",
            "Added image:  762\n",
            "Added image:  763\n",
            "Added image:  764\n",
            "Added image:  765\n",
            "Added image:  766\n",
            "Added image:  767\n",
            "Added image:  768\n",
            "Added image:  769\n",
            "Added image:  770\n",
            "Added image:  771\n",
            "Added image:  772\n",
            "Added image:  773\n",
            "Added image:  774\n",
            "Added image:  775\n",
            "Added image:  776\n",
            "Added image:  777\n",
            "Added image:  778\n",
            "Added image:  779\n",
            "Added image:  780\n",
            "Added image:  781\n",
            "Added image:  782\n",
            "Added image:  783\n",
            "Added image:  784\n",
            "Added image:  785\n",
            "Added image:  786\n",
            "Added image:  787\n",
            "Added image:  788\n",
            "Added image:  789\n",
            "Added image:  790\n",
            "Added image:  791\n",
            "Added image:  792\n",
            "Added image:  793\n",
            "Added image:  794\n",
            "Added image:  795\n",
            "Added image:  796\n",
            "Added image:  797\n",
            "Added image:  798\n",
            "Added image:  799\n",
            "Added image:  800\n",
            "Added image:  801\n",
            "Added image:  802\n",
            "Added image:  803\n",
            "Added image:  804\n",
            "Added image:  805\n",
            "Added image:  806\n",
            "Added image:  807\n",
            "Added image:  808\n",
            "Added image:  809\n",
            "Added image:  810\n",
            "Added image:  811\n",
            "Added image:  812\n",
            "Added image:  813\n",
            "Added image:  814\n",
            "Added image:  815\n",
            "Added image:  816\n",
            "Added image:  817\n",
            "Added image:  818\n",
            "Added image:  819\n",
            "Added image:  820\n",
            "Added image:  821\n",
            "Added image:  822\n",
            "Added image:  823\n",
            "Added image:  824\n",
            "Added image:  825\n",
            "Added image:  826\n",
            "Added image:  827\n",
            "Added image:  828\n",
            "Added image:  829\n",
            "Added image:  830\n",
            "Added image:  831\n",
            "Added image:  832\n",
            "Added image:  833\n",
            "Added image:  834\n",
            "Added image:  835\n",
            "Added image:  836\n",
            "Added image:  837\n",
            "Added image:  838\n",
            "Added image:  839\n",
            "Added image:  840\n",
            "Added image:  841\n",
            "Added image:  842\n",
            "Added image:  843\n",
            "Added image:  844\n",
            "Added image:  845\n",
            "Added image:  846\n",
            "Added image:  847\n",
            "Added image:  848\n",
            "Added image:  849\n",
            "Added image:  850\n",
            "Added image:  851\n",
            "Added image:  852\n",
            "Added image:  853\n",
            "Added image:  854\n",
            "Added image:  855\n",
            "Added image:  856\n",
            "Added image:  857\n",
            "Added image:  858\n",
            "Added image:  859\n",
            "Added image:  860\n",
            "Added image:  861\n",
            "Added image:  862\n",
            "Added image:  863\n",
            "Added image:  864\n",
            "Added image:  865\n",
            "Added image:  866\n",
            "Added image:  867\n",
            "Added image:  868\n",
            "Added image:  869\n",
            "Added image:  870\n",
            "Added image:  871\n",
            "Added image:  872\n",
            "Added image:  873\n",
            "Added image:  874\n",
            "Added image:  875\n",
            "Added image:  876\n",
            "Added image:  877\n",
            "Added image:  878\n",
            "Added image:  879\n",
            "Added image:  880\n",
            "Added image:  881\n",
            "Added image:  882\n",
            "Added image:  883\n",
            "Added image:  884\n",
            "Added image:  885\n",
            "Added image:  886\n",
            "Added image:  887\n",
            "Added image:  888\n",
            "Added image:  889\n",
            "Added image:  890\n",
            "Added image:  891\n",
            "Added image:  892\n",
            "Added image:  893\n",
            "Added image:  894\n",
            "Added image:  895\n",
            "Added image:  896\n",
            "Added image:  897\n",
            "Added image:  898\n",
            "Added image:  899\n",
            "Added image:  900\n",
            "Added image:  901\n",
            "Added image:  902\n",
            "Added image:  903\n",
            "Added image:  904\n",
            "Added image:  905\n",
            "Added image:  906\n",
            "Added image:  907\n",
            "Added image:  908\n",
            "Added image:  909\n",
            "Added image:  910\n",
            "Added image:  911\n",
            "Added image:  912\n",
            "Added image:  913\n",
            "Added image:  914\n",
            "Added image:  915\n",
            "Added image:  916\n",
            "Added image:  917\n",
            "Added image:  918\n",
            "Added image:  919\n",
            "Added image:  920\n",
            "Added image:  921\n",
            "Added image:  922\n",
            "Added image:  923\n",
            "Added image:  924\n",
            "Added image:  925\n",
            "Added image:  926\n",
            "Added image:  927\n",
            "Added image:  928\n",
            "Added image:  929\n",
            "Added image:  930\n",
            "Added image:  931\n",
            "Added image:  932\n",
            "Added image:  933\n",
            "Added image:  934\n",
            "Added image:  935\n",
            "Added image:  936\n",
            "Added image:  937\n",
            "Added image:  938\n",
            "Added image:  939\n",
            "Added image:  940\n",
            "Added image:  941\n",
            "Added image:  942\n",
            "Added image:  943\n",
            "Added image:  944\n",
            "Added image:  945\n",
            "Added image:  946\n",
            "Added image:  947\n",
            "Added image:  948\n",
            "Added image:  949\n",
            "Added image:  950\n",
            "Added image:  951\n",
            "Added image:  952\n",
            "Added image:  953\n",
            "Added image:  954\n",
            "Added image:  955\n",
            "Added image:  956\n",
            "Added image:  957\n",
            "Added image:  958\n",
            "Added image:  959\n",
            "Added image:  960\n",
            "Added image:  961\n",
            "Added image:  962\n",
            "Added image:  963\n",
            "Added image:  964\n",
            "Added image:  965\n",
            "Added image:  966\n",
            "Added image:  967\n",
            "Added image:  968\n",
            "Added image:  969\n",
            "Added image:  970\n",
            "Added image:  971\n",
            "Added image:  972\n",
            "Added image:  973\n",
            "Added image:  974\n",
            "Added image:  975\n",
            "Added image:  976\n",
            "Added image:  977\n",
            "Added image:  978\n",
            "Added image:  979\n",
            "Added image:  980\n",
            "Added image:  981\n",
            "Added image:  982\n",
            "Added image:  983\n",
            "Added image:  984\n",
            "Added image:  985\n",
            "Added image:  986\n",
            "Added image:  987\n",
            "Added image:  988\n",
            "Added image:  989\n",
            "Added image:  990\n",
            "Added image:  991\n",
            "Added image:  992\n",
            "Added image:  993\n",
            "Added image:  994\n",
            "Added image:  995\n",
            "Added image:  996\n",
            "Added image:  997\n",
            "Added image:  998\n",
            "Added image:  999\n",
            "Added image:  1000\n",
            "Added image:  1001\n",
            "Added image:  1002\n",
            "Added image:  1003\n",
            "Added image:  1004\n",
            "Added image:  1005\n",
            "Added image:  1006\n",
            "Added image:  1007\n",
            "Added image:  1008\n",
            "Added image:  1009\n",
            "Added image:  1010\n",
            "Added image:  1011\n",
            "Added image:  1012\n",
            "Added image:  1013\n",
            "Added image:  1014\n",
            "Added image:  1015\n",
            "Added image:  1016\n",
            "Added image:  1017\n",
            "Added image:  1018\n",
            "Added image:  1019\n",
            "Added image:  1020\n",
            "Added image:  1021\n",
            "Added image:  1022\n",
            "Added image:  1023\n",
            "Added image:  1024\n",
            "Added image:  1025\n",
            "Added image:  1026\n",
            "Added image:  1027\n",
            "Added image:  1028\n",
            "Added image:  1029\n",
            "Added image:  1030\n",
            "Added image:  1031\n",
            "Added image:  1032\n",
            "Added image:  1033\n",
            "Added image:  1034\n",
            "Added image:  1035\n",
            "Added image:  1036\n",
            "Added image:  1037\n",
            "Added image:  1038\n",
            "Added image:  1039\n",
            "Added image:  1040\n",
            "Added image:  1041\n",
            "Added image:  1042\n",
            "Added image:  1043\n",
            "Added image:  1044\n",
            "Added image:  1045\n",
            "Added image:  1046\n",
            "Added image:  1047\n",
            "Added image:  1048\n",
            "Added image:  1049\n",
            "Added image:  1050\n",
            "Added image:  1051\n",
            "Added image:  1052\n",
            "Added image:  1053\n",
            "Added image:  1054\n",
            "Added image:  1055\n",
            "Added image:  1056\n",
            "Added image:  1057\n",
            "Added image:  1058\n",
            "Added image:  1059\n",
            "Added image:  1060\n",
            "Added image:  1061\n",
            "Added image:  1062\n",
            "Added image:  1063\n",
            "Added image:  1064\n",
            "Added image:  1065\n",
            "Added image:  1066\n",
            "Added image:  1067\n",
            "Added image:  1068\n",
            "Added image:  1069\n",
            "Added image:  1070\n",
            "Added image:  1071\n",
            "Added image:  1072\n",
            "Added image:  1073\n",
            "Added image:  1074\n",
            "Added image:  1075\n",
            "Added image:  1076\n",
            "Added image:  1077\n",
            "Added image:  1078\n",
            "Added image:  1079\n",
            "Added image:  1080\n",
            "Added image:  1081\n",
            "Added image:  1082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u5JBF-DzzzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877ab202-7eec-4ebc-a566-09abf48f00aa"
      },
      "source": [
        "print(\"Number of images: \", len(images))\n",
        "print(\"Number of labels: \", len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images:  1083\n",
            "Number of labels:  1083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBWXbjG4zzzF"
      },
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "df = pd.DataFrame(images)\n",
        "df['Labels'] = labels\n",
        "\n",
        "x = df.iloc[:, : -1]\n",
        "y = df.iloc[:, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RGSiGX3zzzG"
      },
      "source": [
        "# SVM Model Construction\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# Initializing model\n",
        "svc = svm.SVC(probability = True)\n",
        "params = {'C' : [0.1, 1, 10, 100], 'gamma' : [0.0001, 0.01, 0.1, 1], 'kernel' : ['rbf', 'poly']}\n",
        "model = GridSearchCV(svc, params)\n",
        "\n",
        "# Split the train and test datasets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y)\n",
        "with tf.device('/GPU:0'):\n",
        "  model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Oweyyy6_vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413a4a20-19eb-445f-8e80-dce28a818dd3"
      },
      "source": [
        "tf.config.list_physical_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcg9N2PnzzzI"
      },
      "source": [
        "# Test the trained model\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"Actual:\\n\", y_test)\n",
        "print(\"Predicted:\\n\", y_pred)\n",
        "\n",
        "print(\"Accuracy: \", (accuracy_score(y_pred, y_test) * 100), \"%\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-N4WpzVzzzJ"
      },
      "source": [
        "# Saving the model\n",
        "\n",
        "import pickle\n",
        "\n",
        "fileName = \"arrowClassifier.sav\"\n",
        "modelPath = \"/content/drive/MyDrive/IRC Datasets/Saved Models/SVM\"\n",
        "os.chdir(modelPath)\n",
        "\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}